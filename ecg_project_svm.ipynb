{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ecg_project_svm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naveenhooda2000/IRModelSelection/blob/master/ecg_project_svm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG7gQgjNXFU9",
        "colab_type": "code",
        "outputId": "45556495-de1a-4539-be5e-59153fa0ba4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GQ18Kd5F3uKe",
        "outputId": "4c18ce1d-78ba-4a50-e285-507fd7a006ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install -q https://github.com/neuropsychology/NeuroKit.py/zipball/master"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for neurokit (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB8Y6vB3n_VS",
        "colab_type": "code",
        "outputId": "666fa156-e104-41e1-82d2-270a8bb5bfef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install joblib"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhBpBx56ntgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNVTi0QIYyoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import math\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import neurokit as nk\n",
        "import numpy as np\n",
        "from numpy import where\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "from keras.layers import Dense, LSTM, Dropout, Activation\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore', DeprecationWarning)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suWqTqRHatL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# paths for different type of files\n",
        "ECG_VALUES_FILES_PATH = '/content/drive/My Drive/Final Project/dataset/ecg-bg/data/ECG'\n",
        "DATA_FRAME_FILE_PATH = '/content/drive/My Drive/Final Project/dataset/ecg-bg/ecg_reading_data_frame.csv'\n",
        "META_DATA_FILE_PATH = '/content/drive/My Drive/Final Project/dataset/ecg-bg/data/meta.csv'\n",
        "R_PEAK_DATA_FILE_PATH = '/content/drive/My Drive/Final Project/dataset/ecg-bg/rpeak-data-label.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQZbbhns6sxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_filename_from_path(path):\n",
        "  return (os.path.split(path)[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If97I3EEU4Tf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_input_dataframe(use_data_frame_file = True):\n",
        "  # read the labels from meta data and append them in the end\n",
        "  meta_data_frame = pd.read_csv(META_DATA_FILE_PATH, engine='python',skiprows = 1, names=['Id',\t'Date',\t'Time',\t'Age',\t'Gender',\t'Height',\t'Weight',\t'Hr',\t'G'])\n",
        "  ecg_labels_dict = {}\n",
        "  for index, row in meta_data_frame.iterrows():\n",
        "    if (int(row[\"G\"]) > 140):\n",
        "      ecg_labels_dict[row[\"Id\"]] = 1\n",
        "    else:\n",
        "      ecg_labels_dict[row[\"Id\"]] = 0\n",
        "      # ecg_labels_dict[row[\"Id\"]] = int(row[\"G\"])\n",
        "  # read the ecg values either from pre-calculated file or from each file by file.\n",
        "  ecg_values_data_frame = pd.DataFrame()\n",
        "  if use_data_frame_file:\n",
        "      ecg_values_data_frame = pd.read_csv(DATA_FRAME_FILE_PATH, engine='python')\n",
        "  else:\n",
        "    all_files = glob.glob(ECG_VALUES_FILES_PATH + '/*.csv')\n",
        "    li_df = []\n",
        "    counter = 0\n",
        "    for filename in all_files:\n",
        "      df = pd.read_csv(filename, usecols=[1], engine='python')\n",
        "      df = df.transpose();\n",
        "      df.insert(0, 'fn', extract_filename_from_path(filename))\n",
        "      li_df.append(df)\n",
        "      counter = counter + 1\n",
        "      if counter % 10 == 0:\n",
        "        print(counter)\n",
        "    ecg_values_data_frame = pd.concat(li_df, axis=0, ignore_index=True)\n",
        "  label_serries_arr = []\n",
        "  # iterate over file name column so that we can create a corresponding column for labels to be appended to ecg_values_data_frame\n",
        "  for filename_col in ecg_values_data_frame[['fn']]:\n",
        "    print(ecg_values_data_frame[filename_col].values.shape)\n",
        "    for index, x in np.ndenumerate(ecg_values_data_frame[filename_col].values):\n",
        "      key = x.replace(\".csv\", \"\")\n",
        "      label_serries_arr.append(ecg_labels_dict[key])\n",
        "  label_serries = pd.Series(data=label_serries_arr)\n",
        "  ecg_values_data_frame['labels'] = label_serries\n",
        "  return ecg_values_data_frame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeherpMbhi64",
        "colab_type": "code",
        "outputId": "0be53d64-5abb-46c3-c121-0b58d47f0904",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ecg_values_data_frame_with_file_name = get_input_dataframe()\n",
        "ecg_values_data_frame = ecg_values_data_frame_with_file_name.drop('fn', 1)\n",
        "ecg_values = ecg_values_data_frame.values"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2238,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG5Kze5Eb6hG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dense_data_vals(processed_ecg):\n",
        "  rpeaks_inds = list(processed_ecg['ECG']['R_Peaks'])\n",
        "  ECG_Filtered = list(processed_ecg['df']['ECG_Filtered'])\n",
        "\n",
        "  dense_data_vals = []\n",
        "  len_of_ECG = len(ECG_Filtered) # ECG data sampled at 1000Hz.\n",
        "  left_algn_ecg = 150            # 150 ms left of Rpeak\n",
        "  right_algn_ecg = 250           # 250 ms right of rpeak\n",
        "  sample_step = 1\n",
        "  seg_number = 0\n",
        "  for each_rpeak_ind in rpeaks_inds :\n",
        "      temp_data = []\n",
        "      temp_inds = []\n",
        "      temp_dict = {}\n",
        "      for all_data in range((each_rpeak_ind - left_algn_ecg), (each_rpeak_ind + right_algn_ecg), sample_step) :\n",
        "          temp_inds.append(all_data)\n",
        "          temp_data.append(ECG_Filtered[all_data])\n",
        "      temp_dict['inds'] = temp_inds\n",
        "      temp_dict['sig'] = temp_data\n",
        "      temp_dict['rpeak'] = ECG_Filtered[each_rpeak_ind]\n",
        "      temp_dict['rpeak_ind'] = each_rpeak_ind\n",
        "      temp_dict['seg_number'] = seg_number\n",
        "      dense_data_vals.append(temp_dict)\n",
        "      seg_number += 1\n",
        "  return dense_data_vals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4eJ97EcjDkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getRPeaksLabelledFromFiducialPoints(data_frame):\n",
        "  rpeak_list_labelled = []\n",
        "  for index, row in data_frame.iterrows():\n",
        "    np_temp = row.dropna().to_numpy()\n",
        "    # https://neurokit.readthedocs.io/en/latest/documentation.html\n",
        "    processed_ecg = nk.ecg_process(np_temp,sampling_rate=1000,filter_type='FIR',filter_band='bandpass',filter_frequency=[1, 40],segmenter='hamilton',quality_model='default') \n",
        "    dense_data_vals = get_dense_data_vals(processed_ecg)\n",
        "    rpeak_labeled = []\n",
        "    for dense_data_val in dense_data_vals:\n",
        "        rpeak_labeled.append(dense_data_val['rpeak']);\n",
        "    # append the label\n",
        "    rpeak_labeled.append(row['labels'])\n",
        "    rpeak_list_labelled.append(rpeak_labeled)\n",
        "  return rpeak_list_labelled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVkQ71pkbNwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rpeak_labelled_list = getRPeaksLabelledFromFiducialPoints(ecg_values_data_frame_deleted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWJUQLAZ4gei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(R_PEAK_DATA_FILE_PATH, \"wb\") as fp:\n",
        "  pickle.dump(rpeak_labelled_list, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGbahIZl5cX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(R_PEAK_DATA_FILE_PATH, \"rb\") as fp:   # Unpickling\n",
        "  rpeak_labelled_list_loaded = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhgnvlaEyf2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_training_dataset(input_values, percentage = 0.7):\n",
        "  freqmap = np.array(np.unique(input_values[:, [input_values.shape[1] - 1]].astype(int), return_counts=True)).T\n",
        "  print (freqmap)\n",
        "  freqmap[:,1] = freqmap[:,1].astype(float) * percentage\n",
        "  # stores the required freq of each label\n",
        "  labelCountDict = {};\n",
        "  for label, freq in freqmap:\n",
        "    labelCountDict[label] = float(freq)\n",
        "  print(labelCountDict)\n",
        "  train_arr, test_arr = [], []\n",
        "  # go through each row of input array after removing NaN\n",
        "  for row in input_values:\n",
        "    label_column_index = row[input_values.shape[1] - 1]\n",
        "    # if we still have required freq of label, we add to train dataset or add to test dataset\n",
        "    if labelCountDict[label_column_index] > 0:\n",
        "      train_arr.append(row)\n",
        "      labelCountDict[label_column_index] = labelCountDict[label_column_index] - 1\n",
        "    else:\n",
        "      test_arr.append(row)\n",
        "  return np.array(train_arr), np.array(test_arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih_lXMY87qn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getNumpyNDArray(rpeak_labelled):\n",
        "  features = []\n",
        "  labels = []\n",
        "  for record in rpeak_labelled:\n",
        "    labels.append(record[-1])\n",
        "    record = record[:-1]\n",
        "    features.append(record)\n",
        "  print(features)\n",
        "  features_df = pd.DataFrame(features)\n",
        "  features_numpy_array = np.asarray(features_df)\n",
        "\n",
        "  labels_df = pd.DataFrame(labels)\n",
        "  labels_numpy_array = np.asarray(labels_df)\n",
        "\n",
        "  return np.concatenate((features_numpy_array, labels_numpy_array), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2ZO3CO9KY-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = getNumpyNDArray(rpeak_labelled_list_loaded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z9733U6CNy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = sample_training_dataset(getNumpyNDArray(rpeak_labelled_list_loaded), 0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLtHP06Yw3JX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split into input and outputs\n",
        "train_X, train_y = train[:, :-1], train[:, -1]\n",
        "test_X, test_y = test[:, :-1], test[:, -1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL6NeTa9O9by",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = OneClassSVM(gamma='auto')\n",
        "clf.fit(train_X)\n",
        "y_pred_train = clf.predict(train_X)\n",
        "y_pred_test = clf.predict(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}